name: Inventory Comparison ETL

on:
  schedule:
    # Run daily at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      max_workers:
        description: 'Number of parallel workers'
        required: false
        default: '5'
        type: choice
        options:
          - '3'
          - '5'
          - '10'
          - '15'
      use_location_filter:
        description: 'Filter by location IDs from file'
        required: false
        default: 'true'
        type: boolean

jobs:
  # Optional: Validate location file before running ETL
  validate-location-file:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install pandas
        run: pip install pandas openpyxl

      - name: Validate location file
        run: |
          python3 << 'EOF'
          import pandas as pd
          import sys
          
          try:
              df = pd.read_excel("odoo_locations.xlsx")
              
              print(f"‚úÖ File loaded successfully")
              print(f"üìä Total rows: {len(df)}")
              print(f"üìã Columns: {', '.join(df.columns.tolist())}")
              
              if 'id' not in df.columns:
                  print("‚ùå ERROR: 'id' column not found!")
                  sys.exit(1)
              
              # Check for valid IDs
              valid_ids = df['id'].dropna()
              print(f"‚úÖ Valid location IDs: {len(valid_ids)}")
              
              # Show sample
              print(f"\nüìù Sample IDs: {valid_ids.head(10).tolist()}")
              
              # Check for duplicates
              duplicates = df[df.duplicated('id', keep=False)]
              if not duplicates.empty:
                  print(f"‚ö†Ô∏è Warning: {len(duplicates)} duplicate IDs found")
              
              print("\n‚úÖ Validation passed!")
              
          except FileNotFoundError:
              print("‚ùå File 'odoo_locations.xlsx' not found!")
              sys.exit(1)
          except Exception as e:
              print(f"‚ùå Validation failed: {e}")
              sys.exit(1)
          EOF

  run-etl:
    runs-on: ubuntu-latest
    needs: validate-location-file
    timeout-minutes: 45
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Verify location file exists
        id: check_file
        run: |
          if [ -f "odoo_locations.xlsx" ]; then
            echo "‚úÖ Location file found"
            echo "file_exists=true" >> $GITHUB_OUTPUT
            
            # Show some stats using Python
            python3 << EOF
          import pandas as pd
          df = pd.read_excel("odoo_locations.xlsx")
          print(f"üìä Found {len(df)} location IDs")
          print(f"üìã Columns: {', '.join(df.columns.tolist())}")
          EOF
          else
            echo "‚ö†Ô∏è Location file not found - will run without filters"
            echo "file_exists=false" >> $GITHUB_OUTPUT
          fi
      
      - name: Set up Google Cloud credentials
        id: auth
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
      
      - name: Run Parallelized ETL Script
        env:
          # Odoo Configuration
          ODOO_URL: ${{ vars.ODOO_URL }}
          ODOO_DB: ${{ vars.ODOO_DB }}
          ODOO_USERNAME: ${{ vars.ODOO_USERNAME }}
          ODOO_PASSWORD: ${{ vars.ODOO_PASSWORD }}
          ODOO_BATCH: '200'
          
          # Store API Configuration
          STORE_API_URL: ${{ vars.STORE_API_URL }}
          STORE_API_KEY: ${{ vars.STORE_API_KEY }}
          STORE_BATCH: '200'
          
          # BigQuery Configuration
          BIGQUERY_PROJECT: ${{ vars.BIGQUERY_PROJECT }}
          BIGQUERY_DATASET: ${{ vars.BIGQUERY_DATASET }}
          BIGQUERY_TABLE: ${{ vars.BIGQUERY_TABLE }}
          
          # Location Filter Configuration
          ODOO_LOCATIONS_FILE: 'odoo_locations.xlsx'
          
          # Parallel Execution Settings
          ETL_MAX_WORKERS: ${{ github.event.inputs.max_workers || '5' }}
          
          # Google Cloud Auth (set by auth action)
          GOOGLE_APPLICATION_CREDENTIALS: ${{ steps.auth.outputs.credentials_file_path }}
        run: |
          echo "üöÄ Starting Parallelized ETL..."
          echo "üìä Location filter: ${{ steps.check_file.outputs.file_exists == 'true' && 'Enabled' || 'Disabled' }}"
          echo "‚öôÔ∏è  Max workers: ${{ github.event.inputs.max_workers || '5' }}"
          python data.py
      
      - name: Generate execution summary
        if: always()
        run: |
          echo "## üìä ETL Execution Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Run Time**: $(date -u)" >> $GITHUB_STEP_SUMMARY
          echo "- **Location Filter**: ${{ steps.check_file.outputs.file_exists == 'true' && '‚úÖ Enabled (5,998 locations)' || '‚ö†Ô∏è Disabled' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Max Workers**: ${{ github.event.inputs.max_workers || '5' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Trigger**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ job.status }}" == "success" ]; then
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "### ‚úÖ ETL Completed Successfully" >> $GITHUB_STEP_SUMMARY
            echo "Data has been loaded to BigQuery table: \`${{ vars.BIGQUERY_PROJECT }}.${{ vars.BIGQUERY_DATASET }}.${{ vars.BIGQUERY_TABLE }}\`" >> $GITHUB_STEP_SUMMARY
          fi
      
      - name: Upload logs on failure
        if: failure()
        uses: actions/upload-artifact@v4
        with:
          name: etl-logs-${{ github.run_number }}
          path: |
            *.log
            */*.log
          retention-days: 7
      
      - name: Upload logs on success (optional)
        if: success()
        uses: actions/upload-artifact@v4
        with:
          name: etl-success-logs-${{ github.run_number }}
          path: |
            *.log
            */*.log
          retention-days: 3
      
      - name: Notify on failure
        if: failure()
        run: |
          echo "‚ùå ETL job failed. Check the logs for details."
          echo "Run number: ${{ github.run_number }}"
          echo "Download logs from the Actions artifacts section."
